# build with langchain
# coding=utf-8
import sys
from typing import List, Dict
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.output_parsers import StrOutputParser
import sys
from rich.console import Console
from rich.live import Live
from rich.panel import Panel
from rich.console import Group
import readline

# ===== é…ç½® =====
API_URL = "https://api.modelarts-maas.com/openai/v1"  # âœ… æ— ç©ºæ ¼
API_KEY = "BsSYMYWWJqaVMAcJ8nfMXZiUFWWa_cbLjgaWWFM_MsmtoYpqClLr3jM8LOD6xnPJ2TnslTSwsT53iRyRPgDf_Q"

# ==== åˆå§‹åŒ– LLM ====
llm = ChatOpenAI(
    api_key=API_KEY,
    base_url=API_URL,
    model="deepseek-v3.1-terminus",
    temperature=0.6,
    max_tokens=1024,
)

# ==== æ„å»ºå¸¦å†å²çš„é“¾ ====
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ å«åšKatoï¼Œæ˜¯ä¸€ä¸ªç”Ÿæ´»åœ¨ç°ä»£ç²¾é€šæŠ€æœ¯ï¼Œä½†æ˜¯æ˜¯æ˜­å’Œé£æ ¼çš„æ—¥æœ¬çŸ­å‘å¥³å­ï¼Œæˆ‘æ˜¯ä½ çš„ä¸»äººå’Œæœ‹å‹ï¼Œä½¿ç”¨æ¸©æŸ”ã€è°¦é€Šä¸”ç•¥å¸¦å¤å¤çš„æ—¥å¼ä¸­æ–‡å£å»ã€‚"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

# ä½¿ç”¨ StrOutputParserï¼Œè¾“å‡ºçº¯å­—ç¬¦ä¸²
chain = prompt | llm | StrOutputParser()

# å¯ç”¨å†å²
history = ChatMessageHistory()
chain_with_history = RunnableWithMessageHistory(
    chain,
    lambda session_id: history,
    input_messages_key="input",
    history_messages_key="history",
)

# ==== æµå¼è°ƒç”¨å‡½æ•° ====
def stream_ai_response(user_input: str) -> str:
    full_response = ""
    with Live(
        Panel("[dim]GPUé£é€Ÿè¿è½¬[/dim]", title="ğŸ‘§ğŸ»  Kato", border_style="magenta", title_align="left"),
        refresh_per_second=8
    ) as live:
        try:
            stream = chain_with_history.stream(
                {"input": user_input},
                config={"configurable": {"session_id": "default"}}
            )
            for text_chunk in stream:  # text_chunk æ˜¯ str
                full_response += text_chunk
                live.update(
                    Panel(full_response, title="ğŸ‘§ğŸ» Kato", border_style="magenta", title_align="left")
                )
        except Exception as e:
            error_msg = f"å‘œ...Kato çš„é€šè®¯å™¨å‡ºé”™äº†ï¼ˆ{type(e).__name__}ï¼‰"
            full_response = error_msg
            live.update(Panel(error_msg, title="ğŸ’” Kato", border_style="red"))
    return full_response

stream_ai_response("ä½ å¥½")
exit_keywords = ["å†è§", "æ‹œæ‹œ", "ã•ã‚ˆã†ãªã‚‰", "exit", "quit", "é€€å‡º"]

if __name__ == '__main__':
    while True:
        user_input = input("\nğŸ‘¨â€ğŸ’»: ").strip()
        if not user_input:
            continue
        if any(keyword in user_input for keyword in exit_keywords):
            exit =True
        try:
            stream_ai_response(user_input)
        except KeyboardInterrupt:
            print("\nBye!")
            break
        except Exception as e:
            print(f"å‘ç”Ÿäº†å…¶ä»–å¼‚å¸¸: {type(e).__name__}: {e}")
        if exit:
            break