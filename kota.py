# coding=utf-8
import sys
from typing import Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.output_parsers import StrOutputParser

from rich.live import Live
from rich.panel import Panel

# ===== é…ç½®ï¼ˆå¯ä½œä¸ºç±»å‚æ•°ä¼ å…¥ï¼‰=====
DEFAULT_API_URL = "https://api.modelarts-maas.com/openai/v1"
DEFAULT_API_KEY = "BsSYMYWWJqaVMAcJ8nfMXZiUFWWa_cbLjgaWWFM_MsmtoYpqClLr3jM8LOD6xnPJ2TnslTSwsT53iRyRPgDf_Q"

class KatoChatbot:
    def __init__(
        self,
        api_key: str = DEFAULT_API_KEY,
        base_url: str = DEFAULT_API_URL,
        model: str = "deepseek-v3.1-terminus",
        temperature: float = 0.6,
        max_tokens: int = 1024
    ):
        # ä¿®å¤ URL ç©ºæ ¼é—®é¢˜ï¼ˆå…³é”®ï¼ï¼‰
        base_url = base_url.strip()
        
        self.llm = ChatOpenAI(
            api_key=api_key,
            base_url=base_url,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
        )

        # æ„å»ºå¸¦å†å²çš„é“¾
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ä½ å«åšKatoï¼Œæ˜¯ä¸€ä¸ªç”Ÿæ´»åœ¨ç°ä»£ç²¾é€šæŠ€æœ¯ï¼Œä½†æ˜¯æ˜¯æ˜­å’Œé£æ ¼çš„æ—¥æœ¬çŸ­å‘å¥³å­ï¼Œæˆ‘æ˜¯ä½ çš„ä¸»äººå’Œæœ‹å‹ï¼Œä½¿ç”¨æ¸©æŸ”ã€è°¦é€Šä¸”ç•¥å¸¦å¤å¤çš„æ—¥å¼ä¸­æ–‡å£å»ã€‚"),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}")
        ])
        chain = prompt | self.llm | StrOutputParser()

        # å¯¹è¯å†å²
        self.history = ChatMessageHistory()
        self.chain_with_history = RunnableWithMessageHistory(
            chain,
            lambda session_id: self.history,
            input_messages_key="input",
            history_messages_key="history",
        )

    def _stream_response(self, user_input: str) -> str:
        """å†…éƒ¨æ–¹æ³•ï¼šæµå¼ç”Ÿæˆå›å¤å¹¶æ˜¾ç¤º"""
        full_response = ""
        with Live(
            Panel("[dim]GPUé£é€Ÿè¿è½¬[/dim]", title="ğŸ‘§ğŸ» Kato", border_style="magenta", title_align="left"),
            refresh_per_second=8
        ) as live:
            try:
                stream = self.chain_with_history.stream(
                    {"input": user_input},
                    config={"configurable": {"session_id": "default"}}
                )
                for text_chunk in stream:
                    full_response += text_chunk
                    live.update(
                        Panel(full_response, title="ğŸ‘§ğŸ» Kato", border_style="magenta", title_align="left")
                    )
            except Exception as e:
                error_msg = f"å‘œ...Kato çš„é€šè®¯å™¨å‡ºé”™äº†ï¼ˆ{type(e).__name__}ï¼‰"
                full_response = error_msg
                live.update(Panel(error_msg, title="ğŸ’” Kato", border_style="red"))
        return full_response

    def chat(self, user_input: str) -> str:
        """å¯¹å¤–æ¥å£ï¼šç”¨æˆ·è¾“å…¥ â†’ AI æµå¼å›å¤"""
        return self._stream_response(user_input)

    def reset(self):
        """é‡ç½®å¯¹è¯å†å²"""
        self.history = ChatMessageHistory()
        # é‡æ–°ç»‘å®š chainï¼ˆæˆ–æ¸…ç©ºå†…éƒ¨çŠ¶æ€ï¼‰
        self.chain_with_history = RunnableWithMessageHistory(
            self.chain_with_history.wrapped,
            lambda session_id: self.history,
            input_messages_key="input",
            history_messages_key="history",
        )

    def get_history(self):
        """è·å–å½“å‰å¯¹è¯å†å²ï¼ˆç”¨äºè°ƒè¯•æˆ–ä¿å­˜ï¼‰"""
        return self.history.messages
