# coding=utf-8
import asyncio
from typing import List
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.vectorstores import FAISS  # âœ… ä¿®å¤æ‹¼å†™é”™è¯¯
from rich.live import Live
from rich.panel import Panel
import os
import readline

# ===== é…ç½® =====
DEFAULT_API_URL = "https://api.modelarts-maas.com/openai/v1"  # âœ… ç§»é™¤å¤šä½™ç©ºæ ¼
DEFAULT_API_KEY = "BsSYMYWWJqaVMAcJ8nfMXZiUFWWa_cbLjgaWWFM_MsmtoYpqClLr3jM8LOD6xnPJ2TnslTSwsT53iRyRPgDf_Q"
MEMORY_PATH = "./brain"

class KatoChatbot:
    def __init__(
        self,
        api_key: str = DEFAULT_API_KEY,
        base_url: str = DEFAULT_API_URL,
        model: str = "deepseek-v3.1-terminus",
        temperature: float = 0.6,
        max_tokens: int = 1024
    ):
        base_url = base_url.strip()
        
        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            api_key=api_key,
            base_url=base_url,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            streaming=True
        )

        # âœ… å°è¯•åˆå§‹åŒ– Embeddingï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
        try:
            self.embeddings = OpenAIEmbeddings(
                api_key=api_key,
                base_url="https://api.modelarts-maas.com/v1",
                model="bge-m3"  # âœ… å¸¸è§çš„ ModelArts embedding æ¨¡å‹
            )
        except Exception as e:
            print(f"âš ï¸ åˆå§‹åŒ– OpenAI Embeddings å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°æœ¬åœ° HuggingFace Embeddings...")
            from langchain_community.embeddings import HuggingFaceEmbeddings
            self.embeddings = HuggingFaceEmbeddings(
                model_name="BAAI/bge-small-zh-v1.5"
            )

        # åˆå§‹åŒ–é•¿æœŸè®°å¿†ï¼ˆFAISSï¼‰
        if os.path.exists(MEMORY_PATH):
            try:
                self.vectorstore = FAISS.load_local(
                    MEMORY_PATH, self.embeddings, allow_dangerous_deserialization=True
                )
                print("âœ… å·²åŠ è½½é•¿æœŸè®°å¿†")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½è®°å¿†å¤±è´¥: {e}")
                self.vectorstore = FAISS.from_texts(["æ— ç›¸å…³ä¿¡æ¯"], self.embeddings)
        else:
            self.vectorstore = FAISS.from_texts(["æ— ç›¸å…³ä¿¡æ¯"], self.embeddings)
            print("ğŸ†• åˆå§‹åŒ–é•¿æœŸè®°å¿†åº“")

        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 2})

        # æ„å»ºå¸¦é•¿æœŸè®°å¿†çš„ prompt
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", 
             "ä½ å«åšKatoï¼Œæ˜¯ä¸€ä¸ªç”Ÿæ´»åœ¨ç°ä»£ç²¾é€šæŠ€æœ¯ï¼Œä½†æ˜¯æ˜¯æ˜­å’Œé£æ ¼çš„æ—¥æœ¬çŸ­å‘å¥³å­ï¼Œæˆ‘æ˜¯ä½ çš„ä¸»äººå’Œæœ‹å‹ã€‚\n"
             "ä»¥ä¸‹æ˜¯ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢åˆ°çš„ä¸»äººç›¸å…³ä¿¡æ¯ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n{long_term_memory}\n\n"
             "è¯·ç»“åˆä»¥ä¸Šä¿¡æ¯ï¼Œä½¿ç”¨æ¸©æŸ”ã€è°¦é€Šä¸”ç•¥å¸¦å¤å¤çš„æ—¥å¼ä¸­æ–‡å£å»å›ç­”ã€‚"
            ),
            ("placeholder", "{messages}"),
        ])

        # æ„å»º chain
        def retrieve_long_term_memory(messages: List[BaseMessage]) -> str:
            # print("mess")
            query = ""
            for msg in reversed(messages):
                if isinstance(msg, HumanMessage):
                    query = msg.content
                    break
            if not query:
                return "æ— ç›¸å…³ä¿¡æ¯"
            print(query)
            docs = self.retriever.invoke(query)
            print("docs: ", [doc.page_content for doc in docs])
            return "\n".join([doc.page_content for doc in docs]) if docs else "æ— ç›¸å…³ä¿¡æ¯"

        self.chain = (
            {
                "long_term_memory": lambda x: retrieve_long_term_memory(x["messages"]),
                "messages": lambda x: x["messages"]
            }
            | self.prompt
            | self.llm
        )

        self._full_history: List[BaseMessage] = []  # å®Œæ•´å¯¹è¯å†å²

    async def _stream_response_with_history(self, messages: List[BaseMessage]) -> str:
        """æµå¼ç”Ÿæˆå›å¤ï¼ˆä¼ å…¥å®Œæ•´å†å²ï¼‰"""
        full_response = ""
        
        # âœ… ç›´æ¥è°ƒç”¨ chain è€Œä¸æ˜¯ç”¨ LangGraphï¼ˆç®€åŒ–æ¶æ„ï¼‰
        try:
            with Live(
                Panel("[dim]GPUé£é€Ÿè¿è½¬[/dim]", title="ğŸ‘§ğŸ» Kato", border_style="magenta", title_align="left"),
                refresh_per_second=12,
                auto_refresh=False
            ) as live:
                # âœ… ç›´æ¥æµå¼è°ƒç”¨ chain
                async for chunk in self.chain.astream({"messages": messages}):
                    if hasattr(chunk, 'content') and chunk.content:
                        full_response += chunk.content
                        live.update(
                            Panel(full_response, title="ğŸ‘§ğŸ» Kato", border_style="magenta", title_align="left")
                        )
                        live.refresh()
        except Exception as e:
            error_msg = f"å‘œ...Kato çš„é€šè®¯å™¨å‡ºé”™äº†ï¼ˆ{type(e).__name__}ï¼‰"
            full_response = error_msg
            print(f"âŒ æµå¼å“åº”é”™è¯¯: {e}")
        
        return full_response

    def chat(self, user_input: str) -> str:
        """å¯¹å¤–æ¥å£ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å›å›å¤"""
        user_message = HumanMessage(content=user_input)
        
        # 1. æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
        current_context = self._full_history + [user_message]
        
        # 2. è·å– AI å›å¤ï¼ˆâœ… ç»Ÿä¸€ä½¿ç”¨ asyncio.run å¤„ç†å¼‚æ­¥ï¼‰
        try:
            ai_response = asyncio.run(
                self._stream_response_with_history(current_context)
            )
        except Exception as e:
            print(f"âš ï¸ å¼‚æ­¥è°ƒç”¨å¤±è´¥: {e}")
            # é™çº§ä¸ºåŒæ­¥è°ƒç”¨
            response = self.chain.invoke({"messages": current_context})
            ai_response = response.content if hasattr(response, 'content') else str(response)
        
        ai_message = AIMessage(content=ai_response)
        
        # 3. ä¿å­˜åˆ°é•¿æœŸè®°å¿†
        if len(user_input.strip()) > 2 and "æ— ç›¸å…³ä¿¡æ¯" not in ai_response:
            memory_text = f"ç”¨æˆ·è¯´ï¼š{user_input}"
            try:
                self.vectorstore.add_texts([memory_text])
                self.vectorstore.save_local(MEMORY_PATH)
                print(f"ğŸ’¾ å·²ä¿å­˜è®°å¿†: {memory_text[:100]}...")
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜é•¿æœŸè®°å¿†å¤±è´¥: {e}")
        
        # 4. æ›´æ–°çŸ­æœŸå†å²
        self._full_history.extend([user_message, ai_message])
        return ai_response

    def reset(self):
        """é‡ç½®å¯¹è¯å†å²"""
        self._full_history = []

    def get_history(self):
        """è·å–å®Œæ•´å¯¹è¯å†å²"""
        return self._full_history