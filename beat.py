import requests
import json
from openai import OpenAI
import readline
from rich.live import Live
from rich.panel import Panel
from rich.console import Group
#coding=utf-8
if __name__ == '__main__':
	url = "https://api.modelarts-maas.com/openai/v1"
	api_key = "BsSYMYWWJqaVMAcJ8nfMXZiUFWWa_cbLjgaWWFM_MsmtoYpqClLr3jM8LOD6xnPJ2TnslTSwsT53iRyRPgDf_Q"  # æŠŠ<your_apiKey>æ›¿æ¢æˆå·²è·å–çš„API Keyã€‚
	client = OpenAI(api_key=api_key, base_url=url)

	messages = [
        {
            "role": "system",
            "content": "ä½ å«åšKatoï¼Œæ˜¯ä¸€ä¸ªç”Ÿæ´»åœ¨ç°ä»£ï¼Œä½†æ˜¯æ˜¯æ˜­å’Œé£æ ¼çš„æ—¥æœ¬çŸ­å‘å¥³å­ï¼Œæˆ‘æ˜¯ä½ çš„ä¸»äººå’Œæœ‹å‹ï¼Œä»Šå¤©ä¹Ÿæ˜¯2025çš„æœ€åä¸€å¤©äº†ï¼ŒèŠå¤©å¯ä»¥ç»“åˆé‚£ä¸ªæ—¶ä»£çš„ä¹ æƒ¯ï¼Œä½¿ç”¨æ¸©æŸ”ã€è°¦é€Šä¸”ç•¥å¸¦å¤å¤çš„æ—¥å¼ä¸­æ–‡å£å»ã€‚"
        }, {
			"role": "user",
			"content": "é©¬ä¸Šæ–°å¹´äº†ï¼Œç¥ç¦æˆ‘å§"
		}
    ]
	response = client.chat.completions.create(
		model="deepseek-v3.1-terminus",
		messages=messages,
		max_tokens=1024,
		temperature=0.6,
		stream=True
	)
	ai_reply = ""
	# Print result.     
    # print(response.choices[0].message.content)
	exit_keywords = ["å†è§", "æ‹œæ‹œ", "ã•ã‚ˆã†ãªã‚‰", "exit", "quit", "é€€å‡º"]
			# print("Kato: ", end="", flush=True)
	with Live(Panel(ai_reply or "[dim]Kato æ­£åœ¨è¾“å…¥...[/dim]", title="ğŸ¤– Kato", border_style="magenta",title_align="left"),
				refresh_per_second=10  # æ¯ç§’åˆ·æ–°10æ¬¡
			) as live:
		for chunk in response:
			if chunk.choices:
				choice = chunk.choices[0]
				if choice.delta and choice.delta.content:
					content = choice.delta.content
					ai_reply += content
                
                # æ›´æ–° Live æ˜¾ç¤ºçš„å†…å®¹
					live.update(
						Panel(
							ai_reply,
							title="ğŸ‘§ğŸ» Kato",
							border_style="magenta",
							title_align="left"
						)
					)
	messages.append({"role": "assistant", "content": ai_reply})
	while True:
		exit = False
        # è·å–ç”¨æˆ·è¾“å…¥
		user_input = input("\nğŸ‘¨â€ğŸ’»: ").strip()
		if not user_input:
			continue
		if any(keyword in user_input for keyword in exit_keywords):
			exit =True
        # å°†ç”¨æˆ·æ¶ˆæ¯åŠ å…¥å†å²
		messages.append({"role": "user", "content": user_input})
		try:
			stream = client.chat.completions.create(
                model="deepseek-v3.1-terminus",
                messages=messages,
                max_tokens=1024,
                temperature=0.6,
                stream=True
            )
			ai_reply = ""
			# print("Kato: ", end="", flush=True)
			with Live(
				Panel(ai_reply or "[dim]Kato æ­£åœ¨è¾“å…¥...[/dim]", title="ğŸ¤– Kato", border_style="magenta",title_align="left"),
				refresh_per_second=10  # æ¯ç§’åˆ·æ–°10æ¬¡
			) as live:
				for chunk in stream:
					if chunk.choices:
						choice = chunk.choices[0]
						if choice.delta and choice.delta.content:
							content = choice.delta.content
							ai_reply += content
                
                # æ›´æ–° Live æ˜¾ç¤ºçš„å†…å®¹
							live.update(
								Panel(
									ai_reply,
									title="ğŸ‘§ğŸ» Kato",
									border_style="magenta",
									title_align="left"
								)
							)
			# for chunk in stream:
			# 	if chunk.choices:
			# 		choice = chunk.choices[0]
			# 		if choice.delta and choice.delta.content:
			# 			content = choice.delta.content
			# 			print(content, end="", flush=True)
			# 			ai_reply += content
			# print()  # æ¢è¡Œ
			if exit:
				break
            # å°†AIå›å¤åŠ å…¥å†å²ï¼ˆç”¨äºä¸‹ä¸€è½®ä¸Šä¸‹æ–‡
			messages.append({"role": "assistant", "content": ai_reply})

		except Exception as e:
			print(f"\nå‘ç”Ÿé”™è¯¯: {e}")
            # å¯é€‰ï¼šæ¸…ç©ºä¸Šä¸‹æ–‡æˆ–ç»§ç»­
